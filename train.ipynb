{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e0e8638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Advanced data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest',\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "# Enhanced RICAP or CutMix for better augmentation\n",
    "def cutmix_augmentation(images, labels, alpha=1.0):\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    lam = tf.random.uniform([batch_size], 0, 1)\n",
    "    \n",
    "    # Create mixed images and labels\n",
    "    indices = tf.random.shuffle(tf.range(batch_size))\n",
    "    shuffled_images = tf.gather(images, indices)\n",
    "    shuffled_labels = tf.gather(labels, indices)\n",
    "    \n",
    "    return mixed_images, mixed_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54f0f79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['coffee___healthy', 'coffee___rust', 'coffee__phoma', 'corn_blight', 'corn_common_rust', 'corn_healthy', 'cotton_bacterial_blight', 'cotton_curl_virus', 'cotton_healthy_leaf', 'cotton_herbicide_growth_damage', 'cotton_leaf_hopper_jassids', 'cotton_leaf_redding', 'cotton_leaf_variegation', 'potato___early_blight', 'potato___healthy', 'potato___late_blight', 'rice_bacterialblight', 'rice_brown_spot', 'rice_healthy', 'rice_leafsmut']\n",
      "Train samples: 19479, Val samples: 2902, Test samples: 2481\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import os\n",
    "\n",
    "# 1. Calculate class weights (unchanged)\n",
    "def calculate_class_weights(y_train):\n",
    "    if y_train.ndim > 1:\n",
    "        y_labels = np.argmax(y_train, axis=1)\n",
    "    else:\n",
    "        y_labels = y_train\n",
    "    cw = compute_class_weight('balanced', classes=np.unique(y_labels), y=y_labels)\n",
    "    return dict(enumerate(cw))\n",
    "\n",
    "# 2. Build tf.data.Dataset with oversampling\n",
    "def make_balanced_dataset(image_paths, labels, batch_size=32):\n",
    "    # Convert to Dataset\n",
    "    ds = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    \n",
    "    # Separate by class\n",
    "    class_datasets = {}\n",
    "    for cls in np.unique(labels):\n",
    "        cls_ds = ds.filter(lambda img, lbl, c=cls: tf.equal(lbl, c))\n",
    "        class_datasets[int(cls)] = cls_ds.repeat()  # infinite repetition\n",
    "    \n",
    "    # Compute class counts to set sampling weights\n",
    "    counts = np.bincount(labels)\n",
    "    sampling_weights = counts.sum() / (counts * len(counts))\n",
    "    \n",
    "    # Create a sampling dataset\n",
    "    choices = list(class_datasets.keys())\n",
    "    prob_ds = tf.data.Dataset.from_tensor_slices(sampling_weights).repeat()\n",
    "    \n",
    "    # Sample classes according to weights\n",
    "    balanced_ds = tf.data.experimental.sample_from_datasets(\n",
    "        [class_datasets[c] for c in choices],\n",
    "        weights=sampling_weights.tolist()\n",
    "    )\n",
    "    \n",
    "    # Preprocess and batch\n",
    "    def preprocess(img_path, lbl):\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, [224, 224]) / 255.0\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.random_brightness(img, 0.2)\n",
    "        return img, lbl\n",
    "    \n",
    "    return (balanced_ds\n",
    "            .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "            .shuffle(1000)\n",
    "            .batch(batch_size)\n",
    "            .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "# 3. Corrected focal loss (from previous code)\n",
    "def focal_loss(alpha=0.25, gamma=2.0):\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        y_pred = tf.nn.softmax(y_pred, axis=-1)\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
    "        if y_true.ndim == 1 or y_true.shape[-1] == 1:\n",
    "            y_true_ohe = tf.one_hot(tf.cast(y_true, tf.int32), depth=tf.shape(y_pred)[-1])\n",
    "        else:\n",
    "            y_true_ohe = y_true\n",
    "        cross_entropy = -y_true_ohe * tf.math.log(y_pred)\n",
    "        p_t = tf.reduce_sum(y_true_ohe * y_pred, axis=-1, keepdims=True)\n",
    "        weight = alpha * tf.pow(1 - p_t, gamma)\n",
    "        return tf.reduce_mean(weight * tf.reduce_sum(cross_entropy, axis=-1))\n",
    "    return loss_fn\n",
    "\n",
    "def load_image_paths_and_labels(base_dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    class_names = sorted(os.listdir(base_dir))   # ensure consistent class order\n",
    "    class_indices = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "    \n",
    "    for cls in class_names:\n",
    "        cls_dir = os.path.join(base_dir, cls)\n",
    "        for fname in os.listdir(cls_dir):\n",
    "            fpath = os.path.join(cls_dir, fname)\n",
    "            image_paths.append(fpath)\n",
    "            labels.append(class_indices[cls])\n",
    "    \n",
    "    return image_paths, labels, class_names\n",
    "\n",
    "# Build datasets\n",
    "train_paths, train_labels, class_names = load_image_paths_and_labels(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\ML\\datasets_split\\Train\")\n",
    "val_paths,   val_labels,   _           = load_image_paths_and_labels(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\ML\\datasets_split\\val\")\n",
    "test_paths,  test_labels,  _           = load_image_paths_and_labels(r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\ML\\datasets_split\\Test\")\n",
    "\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Train samples: {len(train_paths)}, Val samples: {len(val_paths)}, Test samples: {len(test_paths)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e420bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, BatchNormalization, GlobalAveragePooling2D, Dense\n",
    "\n",
    "def create_improved_cnn(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        # Block 1\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Block 2\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Block 3\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.25),\n",
    "        \n",
    "        # Block 4\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        # Classification layer\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d47327b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0, ResNet50, VGG16\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "\n",
    "def create_transfer_learning_model(base_model_name='EfficientNetB0', input_shape=(224, 224, 3), num_classes=23):\n",
    "    # Load pre-trained model\n",
    "    if base_model_name == 'EfficientNetB0':\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif base_model_name == 'ResNet50':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif base_model_name == 'VGG16':\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    # Freeze base model layers initially\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Add custom classification head\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dropout(0.3),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Fine-tuning strategy\n",
    "def fine_tune_model(model, base_model, learning_rate=1e-5):\n",
    "    # Unfreeze top layers for fine-tuning\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    # Fine-tune from this layer onwards\n",
    "    fine_tune_at = len(base_model.layers) - 20\n",
    "    \n",
    "    # Freeze all layers except the top ones\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Use lower learning rate for fine-tuning\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate/10),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b78d3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8771 - loss: 0.4561\n",
      "Epoch 1: val_accuracy improved from None to 0.87500, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m967s\u001b[0m 2s/step - accuracy: 0.8787 - loss: 0.4545 - val_accuracy: 0.8750 - val_loss: 0.4546 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722ms/step - accuracy: 0.8877 - loss: 0.4493\n",
      "Epoch 2: val_accuracy did not improve from 0.87500\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m512s\u001b[0m 815ms/step - accuracy: 0.8898 - loss: 0.4489 - val_accuracy: 0.8730 - val_loss: 0.4530 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673ms/step - accuracy: 0.8978 - loss: 0.4463\n",
      "Epoch 3: val_accuracy improved from 0.87500 to 0.87997, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 769ms/step - accuracy: 0.8958 - loss: 0.4464 - val_accuracy: 0.8800 - val_loss: 0.4495 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616ms/step - accuracy: 0.8933 - loss: 0.4456\n",
      "Epoch 4: val_accuracy did not improve from 0.87997\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 707ms/step - accuracy: 0.8978 - loss: 0.4446 - val_accuracy: 0.8757 - val_loss: 0.4490 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674ms/step - accuracy: 0.8996 - loss: 0.4436\n",
      "Epoch 5: val_accuracy improved from 0.87997 to 0.88793, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m484s\u001b[0m 770ms/step - accuracy: 0.9029 - loss: 0.4429 - val_accuracy: 0.8879 - val_loss: 0.4467 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689ms/step - accuracy: 0.9058 - loss: 0.4417\n",
      "Epoch 6: val_accuracy did not improve from 0.88793\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 783ms/step - accuracy: 0.9058 - loss: 0.4417 - val_accuracy: 0.8849 - val_loss: 0.4461 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690ms/step - accuracy: 0.9083 - loss: 0.4411\n",
      "Epoch 7: val_accuracy did not improve from 0.88793\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 783ms/step - accuracy: 0.9091 - loss: 0.4407 - val_accuracy: 0.8876 - val_loss: 0.4465 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636ms/step - accuracy: 0.9070 - loss: 0.4408\n",
      "Epoch 8: val_accuracy did not improve from 0.88793\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 710ms/step - accuracy: 0.9073 - loss: 0.4405 - val_accuracy: 0.8846 - val_loss: 0.4467 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 538ms/step - accuracy: 0.9116 - loss: 0.4395\n",
      "Epoch 9: val_accuracy improved from 0.88793 to 0.88959, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 616ms/step - accuracy: 0.9100 - loss: 0.4398 - val_accuracy: 0.8896 - val_loss: 0.4454 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540ms/step - accuracy: 0.9076 - loss: 0.4400\n",
      "Epoch 10: val_accuracy did not improve from 0.88959\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m387s\u001b[0m 617ms/step - accuracy: 0.9086 - loss: 0.4398 - val_accuracy: 0.8896 - val_loss: 0.4445 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541ms/step - accuracy: 0.9117 - loss: 0.4390\n",
      "Epoch 11: val_accuracy did not improve from 0.88959\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 622ms/step - accuracy: 0.9101 - loss: 0.4392 - val_accuracy: 0.8846 - val_loss: 0.4462 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 561ms/step - accuracy: 0.9162 - loss: 0.4379\n",
      "Epoch 12: val_accuracy improved from 0.88959 to 0.89423, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 647ms/step - accuracy: 0.9126 - loss: 0.4385 - val_accuracy: 0.8942 - val_loss: 0.4442 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 583ms/step - accuracy: 0.9124 - loss: 0.4385\n",
      "Epoch 13: val_accuracy improved from 0.89423 to 0.89954, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m417s\u001b[0m 665ms/step - accuracy: 0.9140 - loss: 0.4383 - val_accuracy: 0.8995 - val_loss: 0.4421 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step - accuracy: 0.9151 - loss: 0.4377\n",
      "Epoch 14: val_accuracy did not improve from 0.89954\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m398s\u001b[0m 633ms/step - accuracy: 0.9137 - loss: 0.4379 - val_accuracy: 0.8985 - val_loss: 0.4417 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step - accuracy: 0.9120 - loss: 0.4381\n",
      "Epoch 15: val_accuracy did not improve from 0.89954\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 635ms/step - accuracy: 0.9116 - loss: 0.4381 - val_accuracy: 0.8995 - val_loss: 0.4415 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step - accuracy: 0.9090 - loss: 0.4388\n",
      "Epoch 16: val_accuracy did not improve from 0.89954\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 635ms/step - accuracy: 0.9118 - loss: 0.4381 - val_accuracy: 0.8869 - val_loss: 0.4440 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 558ms/step - accuracy: 0.9175 - loss: 0.4366\n",
      "Epoch 17: val_accuracy did not improve from 0.89954\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 637ms/step - accuracy: 0.9181 - loss: 0.4366 - val_accuracy: 0.8926 - val_loss: 0.4428 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572ms/step - accuracy: 0.9133 - loss: 0.4371\n",
      "Epoch 18: val_accuracy did not improve from 0.89954\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 648ms/step - accuracy: 0.9152 - loss: 0.4369 - val_accuracy: 0.8889 - val_loss: 0.4439 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 556ms/step - accuracy: 0.9159 - loss: 0.4365\n",
      "Epoch 19: val_accuracy improved from 0.89954 to 0.90219, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 637ms/step - accuracy: 0.9153 - loss: 0.4368 - val_accuracy: 0.9022 - val_loss: 0.4398 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 555ms/step - accuracy: 0.9182 - loss: 0.4360\n",
      "Epoch 20: val_accuracy did not improve from 0.90219\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m398s\u001b[0m 634ms/step - accuracy: 0.9179 - loss: 0.4361 - val_accuracy: 0.8916 - val_loss: 0.4430 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 562ms/step - accuracy: 0.9174 - loss: 0.4361\n",
      "Epoch 21: val_accuracy improved from 0.90219 to 0.90484, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 640ms/step - accuracy: 0.9174 - loss: 0.4363 - val_accuracy: 0.9048 - val_loss: 0.4395 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554ms/step - accuracy: 0.9181 - loss: 0.4359\n",
      "Epoch 22: val_accuracy did not improve from 0.90484\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 630ms/step - accuracy: 0.9164 - loss: 0.4364 - val_accuracy: 0.9012 - val_loss: 0.4403 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - accuracy: 0.9197 - loss: 0.4356\n",
      "Epoch 23: val_accuracy did not improve from 0.90484\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 620ms/step - accuracy: 0.9189 - loss: 0.4357 - val_accuracy: 0.8916 - val_loss: 0.4427 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 544ms/step - accuracy: 0.9188 - loss: 0.4354\n",
      "Epoch 24: val_accuracy did not improve from 0.90484\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 621ms/step - accuracy: 0.9165 - loss: 0.4363 - val_accuracy: 0.8972 - val_loss: 0.4414 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541ms/step - accuracy: 0.9157 - loss: 0.4365\n",
      "Epoch 25: val_accuracy did not improve from 0.90484\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m388s\u001b[0m 619ms/step - accuracy: 0.9186 - loss: 0.4357 - val_accuracy: 0.9009 - val_loss: 0.4396 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548ms/step - accuracy: 0.9175 - loss: 0.4359\n",
      "Epoch 26: val_accuracy did not improve from 0.90484\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 633ms/step - accuracy: 0.9164 - loss: 0.4362 - val_accuracy: 0.8992 - val_loss: 0.4413 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.9173 - loss: 0.4361\n",
      "Epoch 27: val_accuracy improved from 0.90484 to 0.90517, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 678ms/step - accuracy: 0.9182 - loss: 0.4358 - val_accuracy: 0.9052 - val_loss: 0.4395 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590ms/step - accuracy: 0.9178 - loss: 0.4356\n",
      "Epoch 28: val_accuracy did not improve from 0.90517\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 674ms/step - accuracy: 0.9188 - loss: 0.4352 - val_accuracy: 0.9052 - val_loss: 0.4391 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587ms/step - accuracy: 0.9195 - loss: 0.4353\n",
      "Epoch 29: val_accuracy did not improve from 0.90517\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 670ms/step - accuracy: 0.9197 - loss: 0.4352 - val_accuracy: 0.9019 - val_loss: 0.4400 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587ms/step - accuracy: 0.9236 - loss: 0.4342\n",
      "Epoch 30: val_accuracy did not improve from 0.90517\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 669ms/step - accuracy: 0.9212 - loss: 0.4348 - val_accuracy: 0.9052 - val_loss: 0.4395 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step - accuracy: 0.9255 - loss: 0.4335\n",
      "Epoch 31: val_accuracy did not improve from 0.90517\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 675ms/step - accuracy: 0.9213 - loss: 0.4347 - val_accuracy: 0.9045 - val_loss: 0.4394 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587ms/step - accuracy: 0.9200 - loss: 0.4350\n",
      "Epoch 32: val_accuracy did not improve from 0.90517\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 672ms/step - accuracy: 0.9221 - loss: 0.4346 - val_accuracy: 0.9025 - val_loss: 0.4402 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - accuracy: 0.9250 - loss: 0.4337\n",
      "Epoch 33: val_accuracy improved from 0.90517 to 0.90749, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 674ms/step - accuracy: 0.9216 - loss: 0.4345 - val_accuracy: 0.9075 - val_loss: 0.4385 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - accuracy: 0.9206 - loss: 0.4346\n",
      "Epoch 34: val_accuracy did not improve from 0.90749\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 672ms/step - accuracy: 0.9190 - loss: 0.4350 - val_accuracy: 0.9038 - val_loss: 0.4392 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589ms/step - accuracy: 0.9191 - loss: 0.4352\n",
      "Epoch 35: val_accuracy improved from 0.90749 to 0.90849, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 676ms/step - accuracy: 0.9211 - loss: 0.4347 - val_accuracy: 0.9085 - val_loss: 0.4378 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619ms/step - accuracy: 0.9257 - loss: 0.4335\n",
      "Epoch 36: val_accuracy did not improve from 0.90849\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 717ms/step - accuracy: 0.9218 - loss: 0.4343 - val_accuracy: 0.9032 - val_loss: 0.4398 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.9211 - loss: 0.4347\n",
      "Epoch 37: val_accuracy did not improve from 0.90849\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m448s\u001b[0m 714ms/step - accuracy: 0.9195 - loss: 0.4349 - val_accuracy: 0.9058 - val_loss: 0.4386 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668ms/step - accuracy: 0.9162 - loss: 0.4357\n",
      "Epoch 38: val_accuracy improved from 0.90849 to 0.91180, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m474s\u001b[0m 755ms/step - accuracy: 0.9155 - loss: 0.4357 - val_accuracy: 0.9118 - val_loss: 0.4370 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.9193 - loss: 0.4349\n",
      "Epoch 39: val_accuracy did not improve from 0.91180\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 677ms/step - accuracy: 0.9193 - loss: 0.4347 - val_accuracy: 0.9058 - val_loss: 0.4393 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590ms/step - accuracy: 0.9224 - loss: 0.4340\n",
      "Epoch 40: val_accuracy did not improve from 0.91180\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 674ms/step - accuracy: 0.9226 - loss: 0.4339 - val_accuracy: 0.9068 - val_loss: 0.4382 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590ms/step - accuracy: 0.9165 - loss: 0.4354\n",
      "Epoch 41: val_accuracy did not improve from 0.91180\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 673ms/step - accuracy: 0.9220 - loss: 0.4340 - val_accuracy: 0.9108 - val_loss: 0.4382 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - accuracy: 0.9244 - loss: 0.4337\n",
      "Epoch 42: val_accuracy did not improve from 0.91180\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 673ms/step - accuracy: 0.9228 - loss: 0.4341 - val_accuracy: 0.9009 - val_loss: 0.4391 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590ms/step - accuracy: 0.9236 - loss: 0.4337\n",
      "Epoch 43: val_accuracy did not improve from 0.91180\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 675ms/step - accuracy: 0.9219 - loss: 0.4343 - val_accuracy: 0.9078 - val_loss: 0.4382 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.9196 - loss: 0.4347\n",
      "Epoch 44: val_accuracy did not improve from 0.91180\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 677ms/step - accuracy: 0.9203 - loss: 0.4343 - val_accuracy: 0.9108 - val_loss: 0.4371 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590ms/step - accuracy: 0.9252 - loss: 0.4333\n",
      "Epoch 45: val_accuracy did not improve from 0.91180\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 675ms/step - accuracy: 0.9238 - loss: 0.4337 - val_accuracy: 0.9022 - val_loss: 0.4401 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 588ms/step - accuracy: 0.9243 - loss: 0.4335\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 46: val_accuracy did not improve from 0.91180\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 672ms/step - accuracy: 0.9233 - loss: 0.4339 - val_accuracy: 0.9048 - val_loss: 0.4385 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589ms/step - accuracy: 0.9268 - loss: 0.4331\n",
      "Epoch 47: val_accuracy did not improve from 0.91180\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 674ms/step - accuracy: 0.9258 - loss: 0.4331 - val_accuracy: 0.9118 - val_loss: 0.4373 - learning_rate: 2.0000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.9215 - loss: 0.4338\n",
      "Epoch 48: val_accuracy improved from 0.91180 to 0.91247, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 679ms/step - accuracy: 0.9254 - loss: 0.4330 - val_accuracy: 0.9125 - val_loss: 0.4371 - learning_rate: 2.0000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595ms/step - accuracy: 0.9296 - loss: 0.4321\n",
      "Epoch 49: val_accuracy improved from 0.91247 to 0.91578, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 681ms/step - accuracy: 0.9286 - loss: 0.4324 - val_accuracy: 0.9158 - val_loss: 0.4365 - learning_rate: 2.0000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.9293 - loss: 0.4320\n",
      "Epoch 50: val_accuracy did not improve from 0.91578\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 675ms/step - accuracy: 0.9276 - loss: 0.4324 - val_accuracy: 0.9151 - val_loss: 0.4366 - learning_rate: 2.0000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.9244 - loss: 0.4338\n",
      "Epoch 51: val_accuracy did not improve from 0.91578\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 677ms/step - accuracy: 0.9276 - loss: 0.4327 - val_accuracy: 0.9138 - val_loss: 0.4363 - learning_rate: 2.0000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.9260 - loss: 0.4330\n",
      "Epoch 52: val_accuracy did not improve from 0.91578\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 676ms/step - accuracy: 0.9278 - loss: 0.4325 - val_accuracy: 0.9125 - val_loss: 0.4369 - learning_rate: 2.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step - accuracy: 0.9281 - loss: 0.4324\n",
      "Epoch 53: val_accuracy did not improve from 0.91578\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 677ms/step - accuracy: 0.9280 - loss: 0.4324 - val_accuracy: 0.9135 - val_loss: 0.4365 - learning_rate: 2.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590ms/step - accuracy: 0.9227 - loss: 0.4337\n",
      "Epoch 54: val_accuracy did not improve from 0.91578\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 674ms/step - accuracy: 0.9259 - loss: 0.4329 - val_accuracy: 0.9138 - val_loss: 0.4367 - learning_rate: 2.0000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.9248 - loss: 0.4332\n",
      "Epoch 55: val_accuracy improved from 0.91578 to 0.91611, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 681ms/step - accuracy: 0.9262 - loss: 0.4328 - val_accuracy: 0.9161 - val_loss: 0.4358 - learning_rate: 2.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.9318 - loss: 0.4319\n",
      "Epoch 56: val_accuracy improved from 0.91611 to 0.91810, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 687ms/step - accuracy: 0.9294 - loss: 0.4323 - val_accuracy: 0.9181 - val_loss: 0.4354 - learning_rate: 2.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589ms/step - accuracy: 0.9295 - loss: 0.4319\n",
      "Epoch 57: val_accuracy did not improve from 0.91810\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 675ms/step - accuracy: 0.9290 - loss: 0.4321 - val_accuracy: 0.9168 - val_loss: 0.4357 - learning_rate: 2.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step - accuracy: 0.9274 - loss: 0.4329\n",
      "Epoch 58: val_accuracy did not improve from 0.91810\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 676ms/step - accuracy: 0.9283 - loss: 0.4324 - val_accuracy: 0.9151 - val_loss: 0.4361 - learning_rate: 2.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 590ms/step - accuracy: 0.9319 - loss: 0.4315\n",
      "Epoch 59: val_accuracy improved from 0.91810 to 0.91877, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 684ms/step - accuracy: 0.9298 - loss: 0.4319 - val_accuracy: 0.9188 - val_loss: 0.4353 - learning_rate: 2.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596ms/step - accuracy: 0.9245 - loss: 0.4335\n",
      "Epoch 60: val_accuracy did not improve from 0.91877\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 681ms/step - accuracy: 0.9260 - loss: 0.4329 - val_accuracy: 0.9158 - val_loss: 0.4357 - learning_rate: 2.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step - accuracy: 0.9303 - loss: 0.4319\n",
      "Epoch 61: val_accuracy did not improve from 0.91877\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 675ms/step - accuracy: 0.9290 - loss: 0.4322 - val_accuracy: 0.9155 - val_loss: 0.4358 - learning_rate: 2.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step - accuracy: 0.9317 - loss: 0.4311\n",
      "Epoch 62: val_accuracy did not improve from 0.91877\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 678ms/step - accuracy: 0.9315 - loss: 0.4314 - val_accuracy: 0.9125 - val_loss: 0.4364 - learning_rate: 2.0000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 593ms/step - accuracy: 0.9279 - loss: 0.4324\n",
      "Epoch 63: val_accuracy did not improve from 0.91877\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 677ms/step - accuracy: 0.9294 - loss: 0.4320 - val_accuracy: 0.9121 - val_loss: 0.4367 - learning_rate: 2.0000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.9270 - loss: 0.4327\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\n",
      "Epoch 64: val_accuracy did not improve from 0.91877\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 678ms/step - accuracy: 0.9283 - loss: 0.4324 - val_accuracy: 0.9138 - val_loss: 0.4365 - learning_rate: 2.0000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step - accuracy: 0.9267 - loss: 0.4331\n",
      "Epoch 65: val_accuracy did not improve from 0.91877\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 679ms/step - accuracy: 0.9297 - loss: 0.4321 - val_accuracy: 0.9145 - val_loss: 0.4363 - learning_rate: 4.0000e-05\n",
      "Epoch 66/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step - accuracy: 0.9295 - loss: 0.4320\n",
      "Epoch 66: val_accuracy did not improve from 0.91877\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 678ms/step - accuracy: 0.9300 - loss: 0.4319 - val_accuracy: 0.9145 - val_loss: 0.4363 - learning_rate: 4.0000e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.9271 - loss: 0.4325\n",
      "Epoch 67: val_accuracy did not improve from 0.91877\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 677ms/step - accuracy: 0.9297 - loss: 0.4320 - val_accuracy: 0.9141 - val_loss: 0.4362 - learning_rate: 4.0000e-05\n",
      "Epoch 68/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.9322 - loss: 0.4313\n",
      "Epoch 68: val_accuracy did not improve from 0.91877\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 677ms/step - accuracy: 0.9305 - loss: 0.4317 - val_accuracy: 0.9151 - val_loss: 0.4359 - learning_rate: 4.0000e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step - accuracy: 0.9332 - loss: 0.4314\n",
      "Epoch 69: val_accuracy did not improve from 0.91877\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 679ms/step - accuracy: 0.9311 - loss: 0.4317 - val_accuracy: 0.9148 - val_loss: 0.4360 - learning_rate: 4.0000e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.9289 - loss: 0.4321\n",
      "Epoch 70: val_accuracy did not improve from 0.91877\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 677ms/step - accuracy: 0.9296 - loss: 0.4320 - val_accuracy: 0.9155 - val_loss: 0.4359 - learning_rate: 4.0000e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591ms/step - accuracy: 0.9303 - loss: 0.4316\n",
      "Epoch 71: val_accuracy did not improve from 0.91877\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 676ms/step - accuracy: 0.9301 - loss: 0.4318 - val_accuracy: 0.9158 - val_loss: 0.4358 - learning_rate: 4.0000e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.9315 - loss: 0.4313\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\n",
      "Epoch 72: val_accuracy did not improve from 0.91877\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m425s\u001b[0m 676ms/step - accuracy: 0.9309 - loss: 0.4316 - val_accuracy: 0.9155 - val_loss: 0.4359 - learning_rate: 4.0000e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632ms/step - accuracy: 0.9280 - loss: 0.4326\n",
      "Epoch 73: val_accuracy did not improve from 0.91877\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 718ms/step - accuracy: 0.9284 - loss: 0.4324 - val_accuracy: 0.9155 - val_loss: 0.4358 - learning_rate: 8.0000e-06\n",
      "Epoch 74/100\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660ms/step - accuracy: 0.9251 - loss: 0.4330\n",
      "Epoch 74: val_accuracy did not improve from 0.91877\n",
      "\u001b[1m628/628\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m497s\u001b[0m 792ms/step - accuracy: 0.9271 - loss: 0.4325 - val_accuracy: 0.9155 - val_loss: 0.4359 - learning_rate: 8.0000e-06\n",
      "Epoch 74: early stopping\n",
      "Restoring model weights from the end of the best epoch: 59.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# Early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=8,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Compile model with appropriate optimizer\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=focal_loss(gamma=2.0, alpha=0.25),  # Focal loss for imbalance\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Training with callbacks (use train_ds, val_ds)\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=100,\n",
    "    validation_data=val_ds,\n",
    "    # ⚠️ Remove class_weight if using oversampling\n",
    "    # class_weight=class_weights,\n",
    "    callbacks=[early_stopping, reduce_lr, model_checkpoint],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e331174c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Training EfficientNetB0 ---\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape mismatch in layer #1 (named stem_conv)for weight stem_conv/kernel. Weight expects shape (3, 3, 1, 32). Received saved weight with shape (3, 3, 3, 32)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 83\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m arch \u001b[38;5;129;01min\u001b[39;00m architectures:\n\u001b[32m     82\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--- Training \u001b[39m\u001b[38;5;132;01m{\u001b[39;00march\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     model, base_model = \u001b[43mcreate_transfer_learning_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43march\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m     model.compile(\n\u001b[32m     85\u001b[39m         optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     86\u001b[39m         loss=\u001b[33m'\u001b[39m\u001b[33msparse_categorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     87\u001b[39m         metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     88\u001b[39m     )\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Train your model here\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mcreate_transfer_learning_model\u001b[39m\u001b[34m(base_model_name, input_shape, num_classes)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Select base model with pretrained weights\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m base_model_name == \u001b[33m'\u001b[39m\u001b[33mEfficientNetB0\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     base_model = \u001b[43mEfficientNetB0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimagenet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m base_model_name == \u001b[33m'\u001b[39m\u001b[33mResNet50\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     34\u001b[39m     base_model = ResNet50(weights=\u001b[33m'\u001b[39m\u001b[33mimagenet\u001b[39m\u001b[33m'\u001b[39m, include_top=\u001b[38;5;28;01mFalse\u001b[39;00m, input_shape=input_shape)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\OneDrive\\Desktop\\ML\\venv\\Lib\\site-packages\\keras\\src\\applications\\efficientnet.py:571\u001b[39m, in \u001b[36mEfficientNetB0\u001b[39m\u001b[34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name)\u001b[39m\n\u001b[32m    555\u001b[39m \u001b[38;5;129m@keras_export\u001b[39m(\n\u001b[32m    556\u001b[39m     [\n\u001b[32m    557\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mkeras.applications.efficientnet.EfficientNetB0\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    569\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mefficientnetb0\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    570\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEfficientNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m        \u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m        \u001b[49m\u001b[32;43m224\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m        \u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    582\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    583\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mb0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\OneDrive\\Desktop\\ML\\venv\\Lib\\site-packages\\keras\\src\\applications\\efficientnet.py:434\u001b[39m, in \u001b[36mEfficientNet\u001b[39m\u001b[34m(width_coefficient, depth_coefficient, default_size, dropout_rate, drop_connect_rate, depth_divisor, activation, blocks_args, name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, weights_name)\u001b[39m\n\u001b[32m    427\u001b[39m     file_name = name + file_suffix\n\u001b[32m    428\u001b[39m     weights_path = file_utils.get_file(\n\u001b[32m    429\u001b[39m         file_name,\n\u001b[32m    430\u001b[39m         BASE_WEIGHTS_PATH + file_name,\n\u001b[32m    431\u001b[39m         cache_subdir=\u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    432\u001b[39m         file_hash=file_hash,\n\u001b[32m    433\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    436\u001b[39m     model.load_weights(weights)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\OneDrive\\Desktop\\ML\\venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\OneDrive\\Desktop\\ML\\venv\\Lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:452\u001b[39m, in \u001b[36m_set_weights\u001b[39m\u001b[34m(instance, symbolic_weights, weight_values, name, skip_mismatch)\u001b[39m\n\u001b[32m    442\u001b[39m             warnings.warn(\n\u001b[32m    443\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSkipping loading weights for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    444\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdue to mismatch in shape for \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    449\u001b[39m                 stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    450\u001b[39m             )\n\u001b[32m    451\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    453\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mShape mismatch in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    454\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfor weight \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbolic_weights[i].path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    455\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWeight expects shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    456\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mReceived saved weight \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    457\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mwith shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreceived_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    458\u001b[39m         )\n\u001b[32m    459\u001b[39m     symbolic_weights[i].assign(weight_value)\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(instance, \u001b[33m\"\u001b[39m\u001b[33mfinalize_state\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m symbolic_weights:\n",
      "\u001b[31mValueError\u001b[39m: Shape mismatch in layer #1 (named stem_conv)for weight stem_conv/kernel. Weight expects shape (3, 3, 1, 32). Received saved weight with shape (3, 3, 3, 32)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications import EfficientNetB0, ResNet50, VGG16\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "\n",
    "# --- 1. Data Preprocessing ---\n",
    "\n",
    "def preprocess(img_path, label):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)  # Decode images as RGB\n",
    "    img = tf.image.resize(img, [256, 256])       # Resize all images to 256x256 (or 224x224 as per model)\n",
    "    img = img / 255.0                             # Normalize pixel values to [0,1]\n",
    "    return img, label\n",
    "\n",
    "# Example of creating tf.data.Dataset for testing\n",
    "def create_dataset(image_paths, labels, batch_size=32):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "    ds = ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.shuffle(1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# --- 2. Transfer Learning Model Creator ---\n",
    "\n",
    "def create_transfer_learning_model(base_model_name, input_shape=(256, 256, 3), num_classes=23):\n",
    "    # Enforce 3 channels for pretrained model weights compatibility\n",
    "    if input_shape[-1] != 3:\n",
    "        raise ValueError(f\"Input shape must have 3 channels for pretrained ImageNet weights, got {input_shape[-1]}\")\n",
    "\n",
    "    # Select base model with pretrained weights\n",
    "    if base_model_name == 'EfficientNetB0':\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif base_model_name == 'ResNet50':\n",
    "        base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    elif base_model_name == 'VGG16':\n",
    "        base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown base model name: {base_model_name}\")\n",
    "\n",
    "    # Freeze base model layers initially\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Add classification head\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=outputs)\n",
    "    return model, base_model\n",
    "\n",
    "# --- 3. Ensemble Prediction Function ---\n",
    "\n",
    "def create_ensemble_predictions(models, X_test):\n",
    "    all_predictions = []\n",
    "    for model in models:\n",
    "        pred = model.predict(X_test)\n",
    "        all_predictions.append(pred)\n",
    "    # Average the predictions from all models\n",
    "    ensemble_pred_probs = np.mean(all_predictions, axis=0)\n",
    "    # Final class is argmax of averaged probabilities\n",
    "    final_predictions = np.argmax(ensemble_pred_probs, axis=1)\n",
    "    return final_predictions, ensemble_pred_probs\n",
    "\n",
    "# --- 4. Example Usage ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Assume train_paths, train_labels, val_paths, val_labels, test_paths, test_labels are defined and loaded externally\n",
    "    batch_size = 32\n",
    "    num_classes = 23  # Set as required for your dataset\n",
    "    \n",
    "    # Create dataset pipelines\n",
    "    train_ds = create_dataset(train_paths, train_labels, batch_size=batch_size)\n",
    "    val_ds = create_dataset(val_paths, val_labels, batch_size=batch_size)\n",
    "    test_ds = create_dataset(test_paths, test_labels, batch_size=batch_size)\n",
    "\n",
    "    architectures = ['EfficientNetB0', 'ResNet50', 'VGG16']\n",
    "    models = []\n",
    "\n",
    "    for arch in architectures:\n",
    "        print(f\"--- Training {arch} ---\")\n",
    "        model, base_model = create_transfer_learning_model(arch, input_shape=(256, 256, 3), num_classes=num_classes)\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        # Train your model here\n",
    "        model.fit(train_ds, validation_data=val_ds, epochs=10)  # Adjust epochs as needed\n",
    "        # Save the trained model\n",
    "        model.save(f\"{arch}_model.h5\")\n",
    "        models.append(model)\n",
    "\n",
    "    # For inference, load test images as numpy arrays for ensemble prediction\n",
    "    # Here we create a NumPy batch for demonstration\n",
    "    X_test = np.array([img.numpy() for img, _ in test_ds.unbatch().take(100)])  # Take 100 samples, adjust accordingly\n",
    "\n",
    "    # Ensemble predictions\n",
    "    final_preds, ensemble_probs = create_ensemble_predictions(models, X_test)\n",
    "\n",
    "    print(\"Ensemble final predicted classes:\")\n",
    "    print(final_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33bd096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"plant_disease_modelp1.keras\")   # new format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ccc504e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "print(model.input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e519414c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    print(images.shape)  # Should print (batch_size, 224, 224, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84ca596e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Predicted class: coffee___healthy\n",
      "Suggested medicine: No suggestion available\n",
      "\n",
      "Top 3 Predictions:\n",
      "coffee___healthy: 34.08%\n",
      "coffee__phoma: 19.94%\n",
      "corn_healthy: 10.87%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Path to test image\n",
    "img_path = r\"C:\\Users\\ASUS\\OneDrive\\画像\\Screenshots\\Screenshot 2025-09-16 210119.png\"\n",
    "\n",
    "# Preprocess the image (resize to 224x224 to match MobileNetV2)\n",
    "img = image.load_img(img_path, target_size=(224, 224))  \n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0  # normalize like training\n",
    "\n",
    "# Make prediction\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Get predicted class\n",
    "predicted_class = class_names[np.argmax(predictions)]\n",
    "\n",
    "# Suggest medicine\n",
    "medicine = disease_medicine_map.get(predicted_class, \"No suggestion available\")\n",
    "\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "print(\"Suggested medicine:\", medicine)\n",
    "\n",
    "# 🔎 Also print top-3 probabilities for debugging\n",
    "probs = predictions[0]\n",
    "top_indices = probs.argsort()[-3:][::-1]\n",
    "print(\"\\nTop 3 Predictions:\")\n",
    "for i in top_indices:\n",
    "    print(f\"{class_names[i]}: {probs[i]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7a4cd86",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_PrefetchDataset' object has no attribute 'class_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrain_ds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclass_names\u001b[49m)\n",
      "\u001b[31mAttributeError\u001b[39m: '_PrefetchDataset' object has no attribute 'class_names'"
     ]
    }
   ],
   "source": [
    "print(train_ds.class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "825ea0ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not locate function 'loss_fn'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'builtins', 'class_name': 'function', 'config': 'loss_fn', 'registered_name': 'function'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Load the correct model\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m      8\u001b[39m model_path = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mASUS\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mOneDrive\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDesktop\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mML\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mplant_disease_modelp1.keras\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m model = \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m✅ Loaded model from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m model.summary()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\OneDrive\\Desktop\\ML\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:189\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    186\u001b[39m         is_keras_zip = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip \u001b[38;5;129;01mor\u001b[39;00m is_keras_dir \u001b[38;5;129;01mor\u001b[39;00m is_hf:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith((\u001b[33m\"\u001b[39m\u001b[33m.h5\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.hdf5\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format.load_model_from_hdf5(\n\u001b[32m    197\u001b[39m         filepath,\n\u001b[32m    198\u001b[39m         custom_objects=custom_objects,\n\u001b[32m    199\u001b[39m         \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m,\n\u001b[32m    200\u001b[39m         safe_mode=safe_mode,\n\u001b[32m    201\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\OneDrive\\Desktop\\ML\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:365\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    361\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mInvalid filename: expected a `.keras` extension. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    362\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    363\u001b[39m     )\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model_from_fileobj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\OneDrive\\Desktop\\ML\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:442\u001b[39m, in \u001b[36m_load_model_from_fileobj\u001b[39m\u001b[34m(fileobj, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m zf.open(_CONFIG_FILENAME, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    440\u001b[39m     config_json = f.read()\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m model = \u001b[43m_model_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[32m    444\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    446\u001b[39m all_filenames = zf.namelist()\n\u001b[32m    447\u001b[39m extract_dir = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\OneDrive\\Desktop\\ML\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:431\u001b[39m, in \u001b[36m_model_from_config\u001b[39m\u001b[34m(config_json, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m     model = \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\OneDrive\\Desktop\\ML\\venv\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:749\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(config, custom_objects, safe_mode, **kwargs)\u001b[39m\n\u001b[32m    747\u001b[39m     compile_config = config.get(\u001b[33m\"\u001b[39m\u001b[33mcompile_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    748\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compile_config:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m         \u001b[43minstance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompile_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    750\u001b[39m         instance.compiled = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    752\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mshared_object_id\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\OneDrive\\Desktop\\ML\\venv\\Lib\\site-packages\\keras\\src\\trainers\\trainer.py:972\u001b[39m, in \u001b[36mTrainer.compile_from_config\u001b[39m\u001b[34m(self, config)\u001b[39m\n\u001b[32m    961\u001b[39m     warnings.warn(\n\u001b[32m    962\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`compile()` was not called as part of model loading \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    963\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbecause the model\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms `compile()` method is custom. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    969\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    970\u001b[39m     )\n\u001b[32m    971\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m972\u001b[39m config = \u001b[43mserialization_lib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[38;5;28mself\u001b[39m.compile(**config)\n\u001b[32m    974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33moptimizer\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.built:\n\u001b[32m    975\u001b[39m     \u001b[38;5;66;03m# Create optimizer variables.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\OneDrive\\Desktop\\ML\\venv\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:610\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(config, custom_objects, safe_mode, **kwargs)\u001b[39m\n\u001b[32m    606\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not parse config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    608\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mclass_name\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m config \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m config:\n\u001b[32m    609\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m--> \u001b[39m\u001b[32m610\u001b[39m         key: \u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    611\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[32m    612\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    613\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m config.items()\n\u001b[32m    614\u001b[39m     }\n\u001b[32m    616\u001b[39m class_name = config[\u001b[33m\"\u001b[39m\u001b[33mclass_name\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    617\u001b[39m inner_config = config[\u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\OneDrive\\Desktop\\ML\\venv\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:693\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(config, custom_objects, safe_mode, **kwargs)\u001b[39m\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m class_name == \u001b[33m\"\u001b[39m\u001b[33mfunction\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    692\u001b[39m     fn_name = inner_config\n\u001b[32m--> \u001b[39m\u001b[32m693\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_retrieve_class_or_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m        \u001b[49m\u001b[43mregistered_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfull_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Below, handling of all classes.\u001b[39;00m\n\u001b[32m    703\u001b[39m \u001b[38;5;66;03m# First, is it a shared object?\u001b[39;00m\n\u001b[32m    704\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mshared_object_id\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ASUS\\OneDrive\\Desktop\\ML\\venv\\Lib\\site-packages\\keras\\src\\saving\\serialization_lib.py:836\u001b[39m, in \u001b[36m_retrieve_class_or_fn\u001b[39m\u001b[34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[39m\n\u001b[32m    829\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[32m    830\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    831\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not deserialize \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m because \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mits parent module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cannot be imported. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    833\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    834\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m836\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    837\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not locate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    838\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mMake sure custom classes are decorated with \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    839\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m`@keras.saving.register_keras_serializable()`. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    840\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    841\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: Could not locate function 'loss_fn'. Make sure custom classes are decorated with `@keras.saving.register_keras_serializable()`. Full object config: {'module': 'builtins', 'class_name': 'function', 'config': 'loss_fn', 'registered_name': 'function'}"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# Load the correct model\n",
    "# -----------------------------\n",
    "model_path = r\"C:\\Users\\ASUS\\OneDrive\\Desktop\\ML\\plant_disease_modelp1.keras\"\n",
    "model = load_model(model_path)\n",
    "\n",
    "print(f\"\\n✅ Loaded model from: {model_path}\")\n",
    "model.summary()\n",
    "\n",
    "# -----------------------------\n",
    "# Define Classes (order must match training)\n",
    "# -----------------------------\n",
    "class_names = [\n",
    "    \"coffee___healthy\",\n",
    "    \"coffee___rust\",\n",
    "    \"coffee___phoma\",\n",
    "    \"cotton___healthy\",\n",
    "    \"cotton___bacterial_blight\",\n",
    "    \"cotton___curl_virus\",\n",
    "    \"maize___healthy\",\n",
    "    \"maize___leaf_blight\",\n",
    "    \"potato___healthy\",\n",
    "    \"potato___early_blight\",\n",
    "    \"rice___healthy\",\n",
    "    \"rice___blast\"\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# Path to test image\n",
    "# -----------------------------\n",
    "img_path = r\"C:\\Users\\ASUS\\OneDrive\\画像\\Screenshots\\Screenshot 2025-09-16 210119.png\"\n",
    "\n",
    "# Preprocess the image (resize to 224x224 for MobileNetV2)\n",
    "img = image.load_img(img_path, target_size=(224, 224))  \n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0  # normalize\n",
    "\n",
    "# -----------------------------\n",
    "# Make prediction\n",
    "# -----------------------------\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Get predicted class\n",
    "predicted_class = class_names[np.argmax(predictions)]\n",
    "print(\"\\nPredicted class:\", predicted_class)\n",
    "\n",
    "# -----------------------------\n",
    "# Top-3 Predictions\n",
    "# -----------------------------\n",
    "probs = predictions[0]\n",
    "top_indices = probs.argsort()[-3:][::-1]\n",
    "print(\"\\nTop 3 Predictions:\")\n",
    "for i in top_indices:\n",
    "    print(f\"{class_names[i]}: {probs[i]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e162f9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m probs = \u001b[43mpredictions\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(probs):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "probs = predictions[0]\n",
    "for i, p in enumerate(probs):\n",
    "    print(f\"{class_names[i]}: {p:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df8dbd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coffee__phoma 1000\n",
      "coffee___healthy 973\n",
      "coffee___rust 1000\n",
      "corn_blight 910\n",
      "corn_common_rust 1049\n",
      "corn_gray_leaf_spot 401\n",
      "corn_healthy 923\n",
      "cotton_bacterial_blight 1000\n",
      "cotton_curl_virus 1000\n",
      "cotton_healthy_leaf 1000\n",
      "cotton_herbicide_growth_damage 1000\n",
      "cotton_leaf_hopper_jassids 970\n",
      "cotton_leaf_redding 1104\n",
      "cotton_leaf_variegation 781\n",
      "potato___early_blight 1000\n",
      "potato___healthy 922\n",
      "potato___late_blight 1000\n",
      "rice_bacterialblight 1000\n",
      "rice_brown_spot 1000\n",
      "rice_healthy 1041\n",
      "rice_leafsmut 1000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "base_dir = \"datasets_split/Train\"\n",
    "for cls in os.listdir(base_dir):\n",
    "    print(cls, len(os.listdir(os.path.join(base_dir, cls))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a54c773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
